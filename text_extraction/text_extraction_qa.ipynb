{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d9a36b07-754b-41f3-908a-a09bc52de6f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mymac/miniforge3/envs/501r/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from transformers import create_optimizer, AutoTokenizer, DefaultDataCollator, TFAutoModelForSequenceClassification, TFAutoModelForQuestionAnswering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "65da97ac-6cf8-4753-8747-5652f243f964",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_dataset('lucadiliello/newsqa')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "59d7b9d0-3b34-47d5-9129-a4ad7ac77267",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['context', 'question', 'answers', 'key', 'labels'],\n",
       "        num_rows: 74160\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['context', 'question', 'answers', 'key', 'labels'],\n",
       "        num_rows: 4212\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f1ac5286-6745-47d4-a237-45efd598e0fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['context', 'question', 'answers', 'key', 'labels'],\n",
       "        num_rows: 51912\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['context', 'question', 'answers', 'key', 'labels'],\n",
       "        num_rows: 4212\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['context', 'question', 'answers', 'key', 'labels'],\n",
       "        num_rows: 22248\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train/test split\n",
    "train_test_split = dataset['train'].train_test_split(test_size=0.3)\n",
    "train_partition = train_test_split['train']\n",
    "test_partition = train_test_split['test']\n",
    "\n",
    "# Update the dataset\n",
    "dataset['train'] = train_partition\n",
    "dataset['test'] = test_partition\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "01da1ddc-9e90-4e34-b7be-1d36bda95865",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-06 11:36:38.237438: I metal_plugin/src/device/metal_device.cc:1154] Metal device set to: Apple M1 Pro\n",
      "2024-11-06 11:36:38.237469: I metal_plugin/src/device/metal_device.cc:296] systemMemory: 32.00 GB\n",
      "2024-11-06 11:36:38.237480: I metal_plugin/src/device/metal_device.cc:313] maxCacheSize: 10.67 GB\n",
      "2024-11-06 11:36:38.237528: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:306] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2024-11-06 11:36:38.237547: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:272] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n",
      "All PyTorch model weights were used when initializing TFDistilBertForQuestionAnswering.\n",
      "\n",
      "All the weights of TFDistilBertForQuestionAnswering were initialized from the PyTorch model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFDistilBertForQuestionAnswering for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "# Tokenizer and model\n",
    "# model_checkpoint = 'distilbert/distilbert-base-uncased'\n",
    "model_checkpoint = 'mrbach/extractive_question_answering'\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)\n",
    "model = TFAutoModelForQuestionAnswering.from_pretrained(model_checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4f8c172d-9472-479c-810d-209cff1fe30b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note - this function is based on some example code found at https://huggingface.co/docs/transformers/tasks/question_answering\n",
    "def tokenize_and_label(examples):\n",
    "    questions = [q.strip() for q in examples['question']]\n",
    "    inputs = tokenizer(\n",
    "        questions,\n",
    "        examples['context'],\n",
    "        max_length=384,\n",
    "        truncation='only_second',  # Only truncate the context, if needed\n",
    "        return_offsets_mapping=True,\n",
    "        padding='max_length',\n",
    "    )\n",
    "\n",
    "    offset_mapping = inputs.pop('offset_mapping')\n",
    "    answers = examples['answers']\n",
    "    labels = examples['labels']\n",
    "    start_positions = []\n",
    "    end_positions = []\n",
    "\n",
    "    for i, offset in enumerate(offset_mapping):\n",
    "        answer = answers[i]\n",
    "        label = labels[i][0]\n",
    "        start_char = label['start'][0]\n",
    "        end_char = label['end'][0]\n",
    "        sequence_ids = inputs.sequence_ids(i)\n",
    "\n",
    "        # Find the start and end of the context\n",
    "        idx = 0\n",
    "        while sequence_ids[idx] != 1:\n",
    "            idx += 1\n",
    "        context_start = idx\n",
    "        while sequence_ids[idx] == 1:\n",
    "            idx += 1\n",
    "        context_end = idx - 1\n",
    "\n",
    "        # If the answer is not fully inside the context, label it (0, 0)\n",
    "        if offset[context_start][0] > end_char or offset[context_end][1] < start_char:\n",
    "            start_positions.append(0)\n",
    "            end_positions.append(0)\n",
    "            \n",
    "        else:\n",
    "            # Otherwise it's the start and end token positions\n",
    "            idx = context_start\n",
    "            while idx <= context_end and offset[idx][0] <= start_char:\n",
    "                idx += 1\n",
    "            start_positions.append(idx - 1)\n",
    "\n",
    "            idx = context_end\n",
    "            while idx >= context_start and offset[idx][1] >= end_char:\n",
    "                idx -= 1\n",
    "            end_positions.append(idx + 1)\n",
    "\n",
    "    inputs['start_positions'] = start_positions\n",
    "    inputs['end_positions'] = end_positions\n",
    "    \n",
    "    return inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b890a188-3afc-459f-b270-3140d553533b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 51912/51912 [00:21<00:00, 2418.80 examples/s]\n",
      "Map: 100%|██████████| 4212/4212 [00:01<00:00, 2392.49 examples/s]\n",
      "Map: 100%|██████████| 22248/22248 [00:09<00:00, 2416.89 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['context', 'question', 'answers', 'key', 'input_ids', 'attention_mask', 'start_positions', 'end_positions'],\n",
       "        num_rows: 51912\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['context', 'question', 'answers', 'key', 'input_ids', 'attention_mask', 'start_positions', 'end_positions'],\n",
       "        num_rows: 4212\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['context', 'question', 'answers', 'key', 'input_ids', 'attention_mask', 'start_positions', 'end_positions'],\n",
       "        num_rows: 22248\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tokenize and label\n",
    "tokenized_dataset = dataset.map(tokenize_and_label, batched=True)\n",
    "\n",
    "# Remove the original label columns (otherwise the data collator gets confused)\n",
    "tokenized_dataset['train'] = tokenized_dataset['train'].remove_columns(['labels'])\n",
    "tokenized_dataset['test'] = tokenized_dataset['test'].remove_columns(['labels'])\n",
    "tokenized_dataset['validation'] = tokenized_dataset['validation'].remove_columns(['labels'])\n",
    "\n",
    "tokenized_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d2ab8cc6-26f0-4b7c-a61c-b12f24a8d55b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def answer_first_n(n=5):\n",
    "    for i in range(n):\n",
    "        # Inputs\n",
    "        question = tokenized_dataset['test'][i]['question']\n",
    "        context = tokenized_dataset['test'][i]['context']\n",
    "        true_answer = tokenized_dataset['test'][i]['answers'][0]\n",
    "        inputs = tokenized_dataset['test'][i]['input_ids']\n",
    "        \n",
    "        # Make prediction\n",
    "        scores = model(input_ids=tf.convert_to_tensor(inputs))\n",
    "        start_index = tf.math.argmax(scores['start_logits'], axis=1).numpy()[0]\n",
    "        end_index = tf.math.argmax(scores['end_logits'], axis=1).numpy()[0]\n",
    "        pred_answer = tokenizer.decode(inputs[start_index:end_index + 1])\n",
    "        \n",
    "        # Print the results\n",
    "        print(f'Question: {question}')\n",
    "        print(f'True answer: {true_answer}')\n",
    "        print(f'Predicted answer: {pred_answer}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cf33bcd3-890e-4255-9b47-3dc02c8d386e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: Who was in a standoff with the U.S. over nuclear weapons?\n",
      "True answer: North Korea\n",
      "Predicted answer: tense\n",
      "\n",
      "Question: Which player scored a hat-trick?\n",
      "True answer: Bendtner\n",
      "Predicted answer: nicklas bendtner\n",
      "\n",
      "Question: Where is Momeni being held?\n",
      "True answer: Tehran's notorious Evin Prison\n",
      "Predicted answer: \n",
      "\n",
      "Question: How many people died?\n",
      "True answer: 25\n",
      "Predicted answer: 25\n",
      "\n",
      "Question: What injury was he suffering from?\n",
      "True answer: lost his entire body below the hips.\n",
      "Predicted answer: triumph and unbearable tragedy. andrew kinard testifies before a senate armed services subcommittee on april 29, 2009. but i would not actually know everything that happened until the night was long over. a couple of weeks before july 15, a friend who works with injured troops emailed me to say it was time for andrew's going away party. andrew kinard is a young marine i first met a few years ago at walter reed army medical center in washington where he was recovering from a devastating ied attack in iraq\n",
      "\n"
     ]
    }
   ],
   "source": [
    "answer_first_n()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c01732f3-a33a-4526-9201-50898f912618",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_metrics(n=1000):\n",
    "    exact_matches, f1_scores = [], []\n",
    "\n",
    "    for i in range(n):\n",
    "        true_answer = tokenized_dataset['test'][i]['answers'][0]\n",
    "        inputs = tokenized_dataset['test'][i]['input_ids']\n",
    "        scores = model(input_ids=tf.convert_to_tensor(inputs))\n",
    "        start_index = tf.math.argmax(scores['start_logits'], axis=1).numpy()[0]\n",
    "        end_index = tf.math.argmax(scores['end_logits'], axis=1).numpy()[0]\n",
    "        pred_answer = tokenizer.decode(inputs[start_index:end_index + 1])\n",
    "\n",
    "        exact_matches.append(pred_answer.strip().lower() == true_answer.strip().lower())\n",
    "        true_tokens = set(true_answer.split())\n",
    "        pred_tokens = set(pred_answer.split())\n",
    "        common_tokens = true_tokens.intersection(pred_tokens)\n",
    "        precision = len(common_tokens) / len(pred_tokens) if pred_tokens else 0\n",
    "        recall = len(common_tokens) / len(true_tokens) if true_tokens else 0\n",
    "        if precision + recall == 0:\n",
    "            f1 = 0\n",
    "        else:\n",
    "            f1 = 2 * (precision * recall) / (precision + recall)\n",
    "        f1_scores.append(f1)\n",
    "\n",
    "    # Exact matches\n",
    "    em = sum(exact_matches) / len(exact_matches)\n",
    "\n",
    "    # F1 score\n",
    "    f1 = sum(f1_scores) / len(f1_scores)\n",
    "\n",
    "    # Print the metrics\n",
    "    print(f'Exact matches: {round(em, 3)}')\n",
    "    print(f'F1: {round(f1, 3)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "578ee674-9d3e-40ee-9fac-32fa1a07b50c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exact matches: 0.046\n",
      "F1: 0.062\n"
     ]
    }
   ],
   "source": [
    "test_metrics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "43e3af5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    }
   ],
   "source": [
    "batch_size = 16\n",
    "n_epochs = 1\n",
    "total_train_steps = (len(tokenized_dataset['train']) // batch_size) * n_epochs\n",
    "optimizer, schedule = create_optimizer(init_lr=2e-5, num_warmup_steps=0, num_train_steps=total_train_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "930635d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_collator = DefaultDataCollator(return_tensors='tf')\n",
    "\n",
    "tf_train_set = model.prepare_tf_dataset(\n",
    "    tokenized_dataset['train'],\n",
    "    shuffle=True,\n",
    "    batch_size=batch_size,\n",
    "    collate_fn=data_collator,\n",
    ")\n",
    "\n",
    "tf_validation_set = model.prepare_tf_dataset(\n",
    "    tokenized_dataset['validation'],\n",
    "    shuffle=False,\n",
    "    batch_size=batch_size,\n",
    "    collate_fn=data_collator,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a956d447",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6e71ef18",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-06 11:40:11.822493: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:117] Plugin optimizer for device_type GPU is enabled.\n",
      "2024-11-06 11:40:12.249477: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:961] PluggableGraphOptimizer failed: INVALID_ARGUMENT: Failed to deserialize the `graph_buf`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3244/3244 [==============================] - ETA: 0s - loss: 2.2888"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-06 12:30:10.637515: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:961] PluggableGraphOptimizer failed: INVALID_ARGUMENT: Failed to deserialize the `graph_buf`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: val_loss improved from inf to 1.94571, saving model to ./finetuned_mrbach/extractive_question_answering\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.src.layers.regularization.dropout.Dropout object at 0x17eb36500>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.src.layers.regularization.dropout.Dropout object at 0x17eb36500>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.src.layers.regularization.dropout.Dropout object at 0x30fb5d0f0>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.src.layers.regularization.dropout.Dropout object at 0x30fb5d0f0>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.src.layers.regularization.dropout.Dropout object at 0x30fb5fca0>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.src.layers.regularization.dropout.Dropout object at 0x30fb5fca0>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.src.layers.regularization.dropout.Dropout object at 0x17eb72890>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.src.layers.regularization.dropout.Dropout object at 0x17eb72890>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.src.layers.regularization.dropout.Dropout object at 0x30fb7d480>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.src.layers.regularization.dropout.Dropout object at 0x30fb7d480>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.src.layers.regularization.dropout.Dropout object at 0x30fb7ffa0>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.src.layers.regularization.dropout.Dropout object at 0x30fb7ffa0>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./finetuned_mrbach/extractive_question_answering/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./finetuned_mrbach/extractive_question_answering/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3244/3244 [==============================] - 3089s 948ms/step - loss: 2.2888 - val_loss: 1.9457\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x379c7ba30>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_checkpoint = ModelCheckpoint(f'./finetuned_{model_checkpoint}', save_best_only=True, verbose=1)\n",
    "\n",
    "model.fit(x=tf_train_set, validation_data=tf_validation_set, epochs=n_epochs, callbacks=[model_checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4a3cd43b-def4-4486-9791-83265925bf34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: Who was in a standoff with the U.S. over nuclear weapons?\n",
      "True answer: North Korea\n",
      "Predicted answer: christiane amanpour\n",
      "\n",
      "Question: Which player scored a hat-trick?\n",
      "True answer: Bendtner\n",
      "Predicted answer: nicklas bendtner\n",
      "\n",
      "Question: Where is Momeni being held?\n",
      "True answer: Tehran's notorious Evin Prison\n",
      "Predicted answer: in a section of tehran's notorious evin prison\n",
      "\n",
      "Question: How many people died?\n",
      "True answer: 25\n",
      "Predicted answer: 25\n",
      "\n",
      "Question: What injury was he suffering from?\n",
      "True answer: lost his entire body below the hips.\n",
      "Predicted answer: a devastating ied attack in iraq\n",
      "\n"
     ]
    }
   ],
   "source": [
    "answer_first_n()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "865f562e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exact matches: 0.172\n",
      "F1: 0.17\n"
     ]
    }
   ],
   "source": [
    "test_metrics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "56f9233f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(CNN Student News) -- Record the CNN Special Investigations Unit Classroom Edition: Notes from North Korea when it airs commercial-free on CNN. (A short feature begins at 4:00 a.m. and precedes the program.)\n",
      "\n",
      "\n",
      "\n",
      "Program Overview\n",
      "\n",
      "\n",
      "\n",
      "CNN chief international correspondent Christiane Amanpour travels to North Korea as the New York Philharmonic Orchestra makes a historic visit to one of the world's most closed societies. She examines the tense standoff with the U.S. over nuclear weapons and provides a rare look inside a notorious, top-secret nuclear facility.\n",
      "\n",
      "\n",
      "\n",
      "Grade Levels: 9 -- 12, College\n",
      "\n",
      "\n",
      "\n",
      "Subject Areas: U.S. History, World History, Current Events, Political Science, Government\n",
      "\n",
      "\n",
      "\n",
      "Objectives\n",
      "\n",
      "\n",
      "\n",
      "The CNN Special Investigations Unit Classroom Edition: Notes from North Korea and its corresponding discussion questions and suggested activities challenge students to:\n",
      "\n",
      "\n",
      "\n",
      "Curriculum Connections\n",
      "\n",
      "\n",
      "\n",
      "Social Studies\n",
      "\n",
      "\n",
      "\n",
      "Standard VI. Power, Authority, and Governance: Social studies programs should include experiences that provide for the study of how people create and change structures of power, authority, and governance.\n",
      "\n",
      "\n",
      "\n",
      "The Curriculum Standards for Social Studies (http://www.socialstudies.org/standards/strands/) are published by the National Council for Social Studies (http://ncss.org/).\n",
      "\n",
      "\n",
      "\n",
      "United States History\n",
      "\n",
      "\n",
      "\n",
      "Standard 27. Understands how the Cold War and conflicts in Korea and Vietnam influenced domestic and international politics\n",
      "\n",
      "\n",
      "\n",
      "Level IV [Grade 9-12]\n",
      "\n",
      "\n",
      "\n",
      "Benchmark 1. Understands U.S. foreign policy from the Truman administration to the Johnson administration\n",
      "\n",
      "\n",
      "\n",
      "Standard 30. Understands developments in foreign policy and domestic politics between the Nixon and Clinton presidencies\n",
      "\n",
      "\n",
      "\n",
      "Level IV [Grade 9-12]\n",
      "\n",
      "\n",
      "\n",
      "Benchmark 5. Understands the influence of U.S. foreign policy on international events from Nixon to Clinton\n",
      "\n",
      "\n",
      "\n",
      "Content Knowledge: A Compendium of Standards and Benchmarks for K-12 Education (Copyright 2000 McREL) is published online by Mid-continent Research for Education and Learning (McREL) (http://www.mcrel.org/standards-benchmarks ), 2550 S. Parker Road, Suite 500, Aurora, CO 80014; Telephone: 303/337-0990.\n",
      "\n",
      "\n",
      "\n",
      "World History\n",
      "\n",
      "\n",
      "\n",
      "Standard 44. Understands the search for community, stability, and peace in an interdependent world\n",
      "\n",
      "\n",
      "\n",
      "Level IV [Grade 9-12]\n",
      "\n",
      "\n",
      "\n",
      "Benchmark 11. Understands common arguments of opposition groups in various countries around the world, common solutions they offer, and the position of these ideas with regard to Western economic and strategic interests\n",
      "\n",
      "\n",
      "\n",
      "Content Knowledge: A Compendium of Standards and Benchmarks for K-12 Education (Copyright 2000 McREL) is published online by Mid-continent Research for Education and Learning (McREL) (http://www.mcrel.org/standards-benchmarks ), 2550 S. Parker Road, Suite 500, Aurora, CO 80014; Telephone: 303/337-0990.\n",
      "\n",
      "\n",
      "\n",
      "Civics\n",
      "\n",
      "\n",
      "\n",
      "III. How Does The Government Established By The Constitution Embody The Purposes, Values, And Principles Of American Democracy?\n",
      "\n",
      "\n",
      "\n",
      "4. Major responsibilities of the national government in domestic and foreign policy\n",
      "\n",
      "\n",
      "\n",
      "IV. What Is The Relationship Of The United States To Other Nations And To World Affairs?\n",
      "\n",
      "\n",
      "\n",
      "1. Nation-states\n",
      "\n",
      "\n",
      "\n",
      "2. Interactions among nation-states\n",
      "\n",
      "\n",
      "\n",
      "4. The historical context of United States foreign policy\n",
      "\n",
      "\n",
      "\n",
      "5. Making and implementing United States foreign policy\n",
      "\n",
      "\n",
      "\n",
      "6. The ends and means of United States foreign policy\n",
      "\n",
      "\n",
      "\n",
      "7. Impact of the American concept of democracy and individual rights on the world\n",
      "\n",
      "\n",
      "\n",
      "The National Standards for Civics and Government (http://www.civiced.org/index.php?page=stds) are published by the Center for Civic Education (http://www.civiced.org/).\n",
      "\n",
      "\n",
      "\n",
      "Discussion Questions\n",
      "\n",
      "\n",
      "\n",
      "1. Who is the leader of North Korea? According to the report, how do North Koreans regard this leader? What aspects of his personality are revealed in the program?\n",
      "\n",
      "\n",
      "\n",
      "2. According to the program, North Korea is a \"closed society.\" What does this mean?\n",
      "\n",
      "\n",
      "\n",
      "3. How does the report describe the history of U.S.-North Korea relations? According to the report: What tensions currently exist between these two nations? What humanitarian and political concerns exist in North Korea?\n",
      "\n",
      "\n",
      "\n",
      "4. Why do you think that North Korea invited the New York Philharmonic to play, and decided to open the Yongbyon nuclear facility to the media at this point in time? Why are these events historically and politically significant?\n",
      "\n",
      "\n",
      "\n",
      "5. Who is Madeline Albright? When and where did she meet with Kim Jong-Il?\n"
     ]
    }
   ],
   "source": [
    "print(tokenized_dataset['test'][0]['context'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "59cc9660",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(CNN) -- Trains and text messages made a deadly combination when two locomotives collided head-on last year near Los Angeles, California, witnesses told an investigative panel this week.\n",
      "\n",
      "\n",
      "\n",
      "Firefighters and investigators inspect the wreckage a day after a train collision in California killed 25 people.\n",
      "\n",
      "\n",
      "\n",
      "Metrolink commuter train engineer Robert Sanchez missed a stop signal while trading text messages with a friend on September 12, leading to a collision with a Union Pacific freight train that killed Sanchez and 24 other people in Chatsworth, California.\n",
      "\n",
      "\n",
      "\n",
      "The accident injured 101 people and caused $10.6 million in damages, according to a report by federal investigators.\n",
      "\n",
      "\n",
      "\n",
      "One National Transportation Safety Board member worries other disasters loom on the nation's rail system.\n",
      "\n",
      "\n",
      "\n",
      "\"One train, one day, one crew. It raises questions for me as to what the heck else is going on out there,\" said Kitty Higgins, chairwoman of a two-day NTSB hearing in Washington on the accident.\n",
      "\n",
      "\n",
      "\n",
      "Sanchez violated his employer's safety rules by even having a cell phone in the cab of the locomotive, a supervisor testified.  Watch what investigators found »\n",
      "\n",
      "\n",
      "\n",
      "Phone records show Sanchez was not only texting a friend just 22 seconds before the collision, but he also had made plans to allow the same friend to actually operate the train.\n",
      "\n",
      "\n",
      "\n",
      "This was a text conversation four days before the crash:\n",
      "\n",
      "\n",
      "\n",
      "[Sanchez to friend]: \"I'm REALLY looking forward to getting you in the cab and showing you how to run a locomotive.\"\n",
      "\n",
      "\n",
      "\n",
      "[Friend to Sanchez]: \"OMG dude me too. Running a locomotive. Having all of that in the palms of my hands.\"\n",
      "\n",
      "\n",
      "\n",
      "[Sanchez to friend]: \"I'm gonna do all the radio talkin'...ur gonna run the locomotive & I'm gonna tell u how to do it. \"\n",
      "\n",
      "\n",
      "\n",
      "At the hearing, officials said Sanchez had been caught with a cell phone twice before. Once another employee turned him in, another time a manager called his phone to see if it was with him in the train cab.\n",
      "\n",
      "\n",
      "\n",
      "\"The engineer's cell phone rang. It was in his briefcase on the other side of the train. I told the engineer that he was in violation of our policy,\" Rick Dahl, who was a safety manager with Metrolink at the time of the accident, told the NTSB investigative panel.\n",
      "\n",
      "\n",
      "\n",
      "Federal regulations do not cover cell phone use by train crews.\n",
      "\n",
      "\n",
      "\n",
      "Records also indicate Sanchez previously had allowed unauthorized people to ride in the cab, and one person even sat at the controls while the train was operating, investigators said.\n",
      "\n",
      "\n",
      "\n",
      "Phone company records indicate the Union Pacific freight train conductor, who was not named and who survived, also sent a text message about two minutes before the collision, but no other crew member sent or received any messages while on duty, investigators said.\n",
      "\n",
      "\n",
      "\n",
      "That train crew followed all signals and other procedures properly, according to an NTSB timeline.\n",
      "\n",
      "\n",
      "\n",
      "The Metrolink train stopped at a station for 57 seconds to allow passengers to exit and board the train, according to an animation of the timeline presented at the hearing.\n",
      "\n",
      "\n",
      "\n",
      "\"The engineer is required to call all signals and indications via radio,\" Dahl testified. Sanchez did not call any of the last three signals before the crash, investigators determined.\n",
      "\n",
      "\n",
      "\n",
      "The freight train was supposed to move onto a siding to allow the Metrolink train to pass, but it never got there because the commuter train ignored a stop signal and intercepted it at a curve. The freight train was just emerging from a tunnel in the rugged Topanga Canyon, and the trains were visible to each other in the curve for only about five seconds, according to the report.\n",
      "\n",
      "\n",
      "\n",
      "At the time of impact, the Metrolink train was traveling about 42 mph and the Union Pacific train 41 mph. The freight train braked for two seconds before impact; the commuter train didn't brake at all, according to onboard data recorders.\n",
      "\n",
      "\n",
      "\n",
      "Investigators found no problems with the signals, the trains' brakes and radios or the tracks. The Union Pacific conductor's blood and urine tested positive for marijuana, but\n"
     ]
    }
   ],
   "source": [
    "print(tokenized_dataset['test'][3]['context'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7a6d1014",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive answer: [CLS]\n",
      "Negative answer: [CLS]\n"
     ]
    }
   ],
   "source": [
    "positive_question = 'What does Rihanna think about the heavy chain?'\n",
    "negative_question = 'What is the U.S. military doing?'\n",
    "positive_context = tokenized_dataset['test'][0]['context']\n",
    "negative_context = tokenized_dataset['test'][3]['context']\n",
    "\n",
    "positive_encoding = tokenizer.encode_plus(text=positive_question, text_pair=positive_context)\n",
    "negative_encoding = tokenizer.encode_plus(text=negative_question, text_pair=negative_context)\n",
    "positive_inputs = positive_encoding['input_ids']\n",
    "negative_inputs = negative_encoding['input_ids']\n",
    "\n",
    "positive_scores = model(input_ids=tf.convert_to_tensor(positive_inputs))\n",
    "negative_scores = model(input_ids=tf.convert_to_tensor(negative_inputs))\n",
    "start_index_p = tf.math.argmax(positive_scores['start_logits'], axis=1).numpy()[0]\n",
    "end_index_p = tf.math.argmax(positive_scores['end_logits'], axis=1).numpy()[0]\n",
    "start_index_n = tf.math.argmax(negative_scores['start_logits'], axis=1).numpy()[0]\n",
    "end_index_n = tf.math.argmax(negative_scores['end_logits'], axis=1).numpy()[0]\n",
    "positive_answer = tokenizer.decode(positive_inputs[start_index_p:end_index_p + 1])\n",
    "negative_answer = tokenizer.decode(negative_inputs[start_index_n:end_index_n + 1])\n",
    "\n",
    "print(f'Positive answer: {positive_answer}')\n",
    "print(f'Negative answer: {negative_answer}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "3a5708a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All PyTorch model weights were used when initializing TFAlbertForSequenceClassification.\n",
      "\n",
      "All the weights of TFAlbertForSequenceClassification were initialized from the PyTorch model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFAlbertForSequenceClassification for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "classifier_tok_checkpoint = 'albert/albert-base-v2'\n",
    "classifier_model_checkpoint = './albert/albert-base-v2_finetuned_sentiment/checkpoint-10000/'\n",
    "\n",
    "classifier_tokenizer = AutoTokenizer.from_pretrained(classifier_tok_checkpoint)\n",
    "classifier_model = TFAutoModelForSequenceClassification.from_pretrained(classifier_model_checkpoint, local_files_only=True, num_labels=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "763ef778",
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_encoded = tokenizer(positive_answer, truncation=True, padding='max_length', max_length=35, return_tensors='tf')['input_ids']\n",
    "negative_encoded = tokenizer(negative_answer, truncation=True, padding='max_length', max_length=35, return_tensors='tf')['input_ids']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "a9a5974b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive article predicted class: 0\n",
      "Positive article predicted logits: [0.7568402  0.04390718]\n",
      "Negative article predicted class: 0\n",
      "Negative article predicted logits: [0.60612404 0.01932076]\n"
     ]
    }
   ],
   "source": [
    "positive_pred = classifier_model(input_ids=positive_encoded).logits.numpy()\n",
    "negative_pred = classifier_model(input_ids=negative_encoded).logits.numpy()\n",
    "\n",
    "print(f'Positive article predicted class: {positive_pred.argmax()}')\n",
    "print(f'Positive article predicted logits: {positive_pred[0]}')\n",
    "print(f'Negative article predicted class: {negative_pred.argmax()}')\n",
    "print(f'Negative article predicted logits: {negative_pred[0]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "359d72a1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
