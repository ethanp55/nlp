{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d9a36b07-754b-41f3-908a-a09bc52de6f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mymac/miniforge3/envs/501r/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from transformers import create_optimizer, AutoTokenizer, DefaultDataCollator, TFAutoModelForSequenceClassification, TFAutoModelForQuestionAnswering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "65da97ac-6cf8-4753-8747-5652f243f964",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_dataset('lucadiliello/newsqa')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "59d7b9d0-3b34-47d5-9129-a4ad7ac77267",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['context', 'question', 'answers', 'key', 'labels'],\n",
       "        num_rows: 74160\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['context', 'question', 'answers', 'key', 'labels'],\n",
       "        num_rows: 4212\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f1ac5286-6745-47d4-a237-45efd598e0fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['context', 'question', 'answers', 'key', 'labels'],\n",
       "        num_rows: 51912\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['context', 'question', 'answers', 'key', 'labels'],\n",
       "        num_rows: 4212\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['context', 'question', 'answers', 'key', 'labels'],\n",
       "        num_rows: 22248\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train/test split\n",
    "train_test_split = dataset['train'].train_test_split(test_size=0.3)\n",
    "train_partition = train_test_split['train']\n",
    "test_partition = train_test_split['test']\n",
    "\n",
    "# Update the dataset\n",
    "dataset['train'] = train_partition\n",
    "dataset['test'] = test_partition\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "01da1ddc-9e90-4e34-b7be-1d36bda95865",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mymac/miniforge3/envs/501r/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n",
      "2024-11-07 09:20:28.667948: I metal_plugin/src/device/metal_device.cc:1154] Metal device set to: Apple M1 Pro\n",
      "2024-11-07 09:20:28.667975: I metal_plugin/src/device/metal_device.cc:296] systemMemory: 32.00 GB\n",
      "2024-11-07 09:20:28.667984: I metal_plugin/src/device/metal_device.cc:313] maxCacheSize: 10.67 GB\n",
      "2024-11-07 09:20:28.668037: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:306] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2024-11-07 09:20:28.668077: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:272] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n",
      "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFDistilBertForQuestionAnswering: ['vocab_projector.bias', 'vocab_layer_norm.bias', 'vocab_layer_norm.weight', 'vocab_transform.weight', 'vocab_transform.bias']\n",
      "- This IS expected if you are initializing TFDistilBertForQuestionAnswering from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFDistilBertForQuestionAnswering from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights or buffers of the TF 2.0 model TFDistilBertForQuestionAnswering were not initialized from the PyTorch model and are newly initialized: ['qa_outputs.weight', 'qa_outputs.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# Tokenizer and model\n",
    "# model_checkpoint = 'distilbert/distilbert-base-uncased'\n",
    "model_checkpoint = 'mrbach/extractive_question_answering'\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)\n",
    "model = TFAutoModelForQuestionAnswering.from_pretrained(model_checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4f8c172d-9472-479c-810d-209cff1fe30b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note - this function is based on some example code found at https://huggingface.co/docs/transformers/tasks/question_answering\n",
    "def tokenize_and_label(examples):\n",
    "    questions = [q.strip() for q in examples['question']]\n",
    "    inputs = tokenizer(\n",
    "        questions,\n",
    "        examples['context'],\n",
    "        max_length=384,\n",
    "        truncation='only_second',  # Only truncate the context, if needed\n",
    "        return_offsets_mapping=True,\n",
    "        padding='max_length',\n",
    "    )\n",
    "\n",
    "    offset_mapping = inputs.pop('offset_mapping')\n",
    "    answers = examples['answers']\n",
    "    labels = examples['labels']\n",
    "    start_positions = []\n",
    "    end_positions = []\n",
    "\n",
    "    for i, offset in enumerate(offset_mapping):\n",
    "        answer = answers[i]\n",
    "        label = labels[i][0]\n",
    "        start_char = label['start'][0]\n",
    "        end_char = label['end'][0]\n",
    "        sequence_ids = inputs.sequence_ids(i)\n",
    "\n",
    "        # Find the start and end of the context\n",
    "        idx = 0\n",
    "        while sequence_ids[idx] != 1:\n",
    "            idx += 1\n",
    "        context_start = idx\n",
    "        while sequence_ids[idx] == 1:\n",
    "            idx += 1\n",
    "        context_end = idx - 1\n",
    "\n",
    "        # If the answer is not fully inside the context, label it (0, 0)\n",
    "        if offset[context_start][0] > end_char or offset[context_end][1] < start_char:\n",
    "            start_positions.append(0)\n",
    "            end_positions.append(0)\n",
    "            \n",
    "        else:\n",
    "            # Otherwise it's the start and end token positions\n",
    "            idx = context_start\n",
    "            while idx <= context_end and offset[idx][0] <= start_char:\n",
    "                idx += 1\n",
    "            start_positions.append(idx - 1)\n",
    "\n",
    "            idx = context_end\n",
    "            while idx >= context_start and offset[idx][1] >= end_char:\n",
    "                idx -= 1\n",
    "            end_positions.append(idx + 1)\n",
    "\n",
    "    inputs['start_positions'] = start_positions\n",
    "    inputs['end_positions'] = end_positions\n",
    "    \n",
    "    return inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b890a188-3afc-459f-b270-3140d553533b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 51912/51912 [00:27<00:00, 1899.78 examples/s]\n",
      "Map: 100%|██████████| 22248/22248 [00:11<00:00, 2018.14 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['context', 'question', 'answers', 'key', 'input_ids', 'attention_mask', 'start_positions', 'end_positions'],\n",
       "        num_rows: 51912\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['context', 'question', 'answers', 'key', 'input_ids', 'attention_mask', 'start_positions', 'end_positions'],\n",
       "        num_rows: 4212\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['context', 'question', 'answers', 'key', 'input_ids', 'attention_mask', 'start_positions', 'end_positions'],\n",
       "        num_rows: 22248\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tokenize and label\n",
    "tokenized_dataset = dataset.map(tokenize_and_label, batched=True)\n",
    "\n",
    "# Remove the original label columns (otherwise the data collator gets confused)\n",
    "tokenized_dataset['train'] = tokenized_dataset['train'].remove_columns(['labels'])\n",
    "tokenized_dataset['test'] = tokenized_dataset['test'].remove_columns(['labels'])\n",
    "tokenized_dataset['validation'] = tokenized_dataset['validation'].remove_columns(['labels'])\n",
    "\n",
    "tokenized_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d2ab8cc6-26f0-4b7c-a61c-b12f24a8d55b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def answer_first_n(n=5):\n",
    "    for i in range(n):\n",
    "        # Inputs\n",
    "        question = tokenized_dataset['test'][i]['question']\n",
    "        context = tokenized_dataset['test'][i]['context']\n",
    "        true_answer = tokenized_dataset['test'][i]['answers'][0]\n",
    "        inputs = tokenized_dataset['test'][i]['input_ids']\n",
    "        \n",
    "        # Make prediction\n",
    "        scores = model(input_ids=tf.convert_to_tensor(inputs))\n",
    "        start_index = tf.math.argmax(scores['start_logits'], axis=1).numpy()[0]\n",
    "        end_index = tf.math.argmax(scores['end_logits'], axis=1).numpy()[0]\n",
    "        pred_answer = tokenizer.decode(inputs[start_index:end_index + 1])\n",
    "        \n",
    "        # Print the results\n",
    "        print(f'Question: {question}')\n",
    "        print(f'True answer: {true_answer}')\n",
    "        print(f'Predicted answer: {pred_answer}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cf33bcd3-890e-4255-9b47-3dc02c8d386e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: What was the aim of the voyage?\n",
      "True answer: find a way to scoop up the plastic waste and devise a way to turn it into a future fuel source.\n",
      "Predicted answer: \n",
      "\n",
      "Question: Where was the daughter kept?\n",
      "True answer: specially designed cellar beneath her father's home in Amstetten, Austria,\n",
      "Predicted answer: [CLS] where was the daughter kept? [SEP] ( cnn ) - - josef fritzl, the austrian accused of keeping his daughter in a cellar for decades and fathering her seven children, will plead guilty to rape and incest when his trial opens monday, fritzl's lawyer told cnn. josef fritzl is expected to plead guilty to rape and incest on monday, his lawyer tells cnn. however, fritzl will deny other charge he faces : murder, enslavement and assault, attorney rudolph mayer said sunday. the 73 - year - old expects to spend the rest of his life in prison, mayer added. fritzl faces six charges in a closed - door trial. the trial is scheduled to last five days, but mayer said it could be shorter. fritzl was charged in november with incest and the repeated rape of his daughter, elisabeth, over a 24 - year period. but he was also charged with the murder of one of the children he fathered with her, an infant who died soon after birth. state prosecutor gerhard sedlacek said michael fritzl died from lack of medical care. in all, fritzl is charged with : murder, involvement in slave trade ( slavery ), rape, incest, assault and deprivation of liberty, sedlacek's office said. if convicted, he could face life in prison. austria does not have the death penalty. \" this man obviously led a double life for 24 years. he had a wife and had seven kids with her. and then he had another family with his daughter, fathered another seven children with her, \" said franz polzer, a police officer in amstetten, the town where fritzl lived, at the time of his arrest. the case first came to light in april 2008 when elisabeth\n",
      "\n",
      "Question: Who does Honoré believe should face jail time?\n",
      "True answer: BP and the government bureaucrats\n",
      "Predicted answer: [CLS] who does honore believe should face jail time? [SEP] ( cnn ) - - it's interesting how many people have swallowed the bp public relations'bait to call the explosion from deepwater horizon oil rig the gulf oil spill. we need to call it what it is : the bp oil spill. the federal government needs to take control and take punitive action against bp and any negligent government regulators immediately. as a concerned citizen, preparedness speaker and author, and former commander of federal troops in disaster response, i watched with interest as bp brought out its big pr guns to protect its brand and its platoon of expert engineers, paid by bp to talk about how it happened and how they intended to fix it. bp's reaction was much like toyota's when it was confronted with safety issues. it, too, focused on pr to protect its brand, versus telling the truth, and sent out its engineers to talk about the problem and the fix. the u. s. coast guard was the first responder. the coast guard's priority always is to save lives. they spent days looking for the 11 missing men. meanwhile, bp took advantage of this time to make itself the authoritative voice in the news about the spill and blame other companies. the u. s. government response was based on laws and rules that were created after the\n",
      "\n",
      "Question: for what reason did Jon Obi Mikel withdraw from Nigeria squad?\n",
      "True answer: Injuries\n",
      "Predicted answer: [CLS] for what reason did jon obi mikel withdraw from nigeria squad? [SEP] ( cnn ) - - injuries continue to strike down the planet's top football players ahead of this month's world cup in south africa, with dutch star arjen robben's participation in doubt and key nigeria midfielder jon obi mikel forced to withdraw. robben, whose inspired form this season took german club bayern munich to the final of the champions league, has not joined his teammates in flying to africa after suffering a hamstring injury on saturday. he scored two goals after coming on as a second - half substitute in a 6 - 1 friendly romp over hungary in amsterdam, but needs a scan on sunday after hurting himself trying to execute a fancy backheel pass. \" i would rather lose this match and have arjen stay fit, \" netherlands coach bert van marwijk said on dutch web site www. vi. nl. \" he felt a sharp pain. that does not bode well. but i do not lose hope. \" robben had returned to action after missing tuesday's 4 - 1 international friendly rout over ghana in rotterdam on tuesday. earlier on saturday, nigeria officials reported that mikel has decided he has not recovered sufficiently from knee surgery, meaning he joins teammates michael ballack ( germany ), michael essien ( ghana ) and jose bosingwa ( portugal ) from his english club chelsea in missing the tournament. the 23 -\n",
      "\n",
      "Question: Who testified about Vance's abuse as a child?\n",
      "True answer: mother, Jacqueline\n",
      "Predicted answer: [CLS] who testified about vance's abuse as a child? [SEP] ( cnn ) - - a jury sentenced an arkansas man to life in prison without parole for killing a television anchor, officials said thursday. the pulaski county, arkansas, jury on wednesday convicted curtis lavelle vance, 29, of capital murder, residential burglary, rape and theft of property in the october 2008 slaying of anne pressly, 26. pressly, the morning news anchor for cnn affiliate katv, was found beaten and unconscious in her home. she died five days later. vance's sentencing phase began after he was convicted wednesday of capital murder, rape and burglary. jurors were tasked with deciding whether the aggravating circumstances in favor of the death penalty outweighed the mitigating circumstances. \" tonight, they have come back with a sentence, a sentence that they believe, and we share with them, is the harshest possible sentence for this gentleman going forward, where he will now spend the rest of his natural life in a 6 - by - 9 cell with nothing to think about but what he has done, \" said guy cannady, stepfather of the victim. \" it's not until he's carried out of tucker max in a pine box will he really meet his true judgment, \" cannady added, referring to arkansas'tucker maximum security prison. he said he was not disappointed that vance did not receive the death penalty. prosecutor larry jegley said the jury gave vance \" everything they could give him except the death penalty. \" asked\n",
      "\n"
     ]
    }
   ],
   "source": [
    "answer_first_n()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c01732f3-a33a-4526-9201-50898f912618",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_metrics(n=1000):\n",
    "    exact_matches, f1_scores = [], []\n",
    "\n",
    "    for i in range(n):\n",
    "        true_answer = tokenized_dataset['test'][i]['answers'][0]\n",
    "        inputs = tokenized_dataset['test'][i]['input_ids']\n",
    "        scores = model(input_ids=tf.convert_to_tensor(inputs))\n",
    "        start_index = tf.math.argmax(scores['start_logits'], axis=1).numpy()[0]\n",
    "        end_index = tf.math.argmax(scores['end_logits'], axis=1).numpy()[0]\n",
    "        pred_answer = tokenizer.decode(inputs[start_index:end_index + 1])\n",
    "\n",
    "        exact_matches.append(pred_answer.strip().lower() == true_answer.strip().lower())\n",
    "        true_tokens = set(true_answer.split())\n",
    "        pred_tokens = set(pred_answer.split())\n",
    "        common_tokens = true_tokens.intersection(pred_tokens)\n",
    "        precision = len(common_tokens) / len(pred_tokens) if pred_tokens else 0\n",
    "        recall = len(common_tokens) / len(true_tokens) if true_tokens else 0\n",
    "        if precision + recall == 0:\n",
    "            f1 = 0\n",
    "        else:\n",
    "            f1 = 2 * (precision * recall) / (precision + recall)\n",
    "        f1_scores.append(f1)\n",
    "\n",
    "    # Exact matches\n",
    "    em = sum(exact_matches) / len(exact_matches)\n",
    "\n",
    "    # F1 score\n",
    "    f1 = sum(f1_scores) / len(f1_scores)\n",
    "\n",
    "    # Print the metrics\n",
    "    print(f'Exact matches: {round(em, 3)}')\n",
    "    print(f'F1: {round(f1, 3)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "578ee674-9d3e-40ee-9fac-32fa1a07b50c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exact matches: 0.046\n",
      "F1: 0.062\n"
     ]
    }
   ],
   "source": [
    "test_metrics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "43e3af5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    }
   ],
   "source": [
    "batch_size = 16\n",
    "n_epochs = 1\n",
    "total_train_steps = (len(tokenized_dataset['train']) // batch_size) * n_epochs\n",
    "optimizer, schedule = create_optimizer(init_lr=2e-5, num_warmup_steps=0, num_train_steps=total_train_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "930635d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_collator = DefaultDataCollator(return_tensors='tf')\n",
    "\n",
    "tf_train_set = model.prepare_tf_dataset(\n",
    "    tokenized_dataset['train'],\n",
    "    shuffle=True,\n",
    "    batch_size=batch_size,\n",
    "    collate_fn=data_collator,\n",
    ")\n",
    "\n",
    "tf_validation_set = model.prepare_tf_dataset(\n",
    "    tokenized_dataset['validation'],\n",
    "    shuffle=False,\n",
    "    batch_size=batch_size,\n",
    "    collate_fn=data_collator,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a956d447",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6e71ef18",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-06 11:40:11.822493: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:117] Plugin optimizer for device_type GPU is enabled.\n",
      "2024-11-06 11:40:12.249477: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:961] PluggableGraphOptimizer failed: INVALID_ARGUMENT: Failed to deserialize the `graph_buf`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3244/3244 [==============================] - ETA: 0s - loss: 2.2888"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-06 12:30:10.637515: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:961] PluggableGraphOptimizer failed: INVALID_ARGUMENT: Failed to deserialize the `graph_buf`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: val_loss improved from inf to 1.94571, saving model to ./finetuned_mrbach/extractive_question_answering\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.src.layers.regularization.dropout.Dropout object at 0x17eb36500>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.src.layers.regularization.dropout.Dropout object at 0x17eb36500>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.src.layers.regularization.dropout.Dropout object at 0x30fb5d0f0>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.src.layers.regularization.dropout.Dropout object at 0x30fb5d0f0>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.src.layers.regularization.dropout.Dropout object at 0x30fb5fca0>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.src.layers.regularization.dropout.Dropout object at 0x30fb5fca0>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.src.layers.regularization.dropout.Dropout object at 0x17eb72890>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.src.layers.regularization.dropout.Dropout object at 0x17eb72890>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.src.layers.regularization.dropout.Dropout object at 0x30fb7d480>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.src.layers.regularization.dropout.Dropout object at 0x30fb7d480>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.src.layers.regularization.dropout.Dropout object at 0x30fb7ffa0>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.src.layers.regularization.dropout.Dropout object at 0x30fb7ffa0>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./finetuned_mrbach/extractive_question_answering/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./finetuned_mrbach/extractive_question_answering/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3244/3244 [==============================] - 3089s 948ms/step - loss: 2.2888 - val_loss: 1.9457\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x379c7ba30>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_checkpoint = ModelCheckpoint(f'./finetuned_{model_checkpoint}', save_best_only=True, verbose=1)\n",
    "\n",
    "model.fit(x=tf_train_set, validation_data=tf_validation_set, epochs=n_epochs, callbacks=[model_checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4a3cd43b-def4-4486-9791-83265925bf34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: Who was in a standoff with the U.S. over nuclear weapons?\n",
      "True answer: North Korea\n",
      "Predicted answer: christiane amanpour\n",
      "\n",
      "Question: Which player scored a hat-trick?\n",
      "True answer: Bendtner\n",
      "Predicted answer: nicklas bendtner\n",
      "\n",
      "Question: Where is Momeni being held?\n",
      "True answer: Tehran's notorious Evin Prison\n",
      "Predicted answer: in a section of tehran's notorious evin prison\n",
      "\n",
      "Question: How many people died?\n",
      "True answer: 25\n",
      "Predicted answer: 25\n",
      "\n",
      "Question: What injury was he suffering from?\n",
      "True answer: lost his entire body below the hips.\n",
      "Predicted answer: a devastating ied attack in iraq\n",
      "\n"
     ]
    }
   ],
   "source": [
    "answer_first_n()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "865f562e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exact matches: 0.172\n",
      "F1: 0.17\n"
     ]
    }
   ],
   "source": [
    "test_metrics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "56f9233f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(CNN Student News) -- Record the CNN Special Investigations Unit Classroom Edition: Notes from North Korea when it airs commercial-free on CNN. (A short feature begins at 4:00 a.m. and precedes the program.)\n",
      "\n",
      "\n",
      "\n",
      "Program Overview\n",
      "\n",
      "\n",
      "\n",
      "CNN chief international correspondent Christiane Amanpour travels to North Korea as the New York Philharmonic Orchestra makes a historic visit to one of the world's most closed societies. She examines the tense standoff with the U.S. over nuclear weapons and provides a rare look inside a notorious, top-secret nuclear facility.\n",
      "\n",
      "\n",
      "\n",
      "Grade Levels: 9 -- 12, College\n",
      "\n",
      "\n",
      "\n",
      "Subject Areas: U.S. History, World History, Current Events, Political Science, Government\n",
      "\n",
      "\n",
      "\n",
      "Objectives\n",
      "\n",
      "\n",
      "\n",
      "The CNN Special Investigations Unit Classroom Edition: Notes from North Korea and its corresponding discussion questions and suggested activities challenge students to:\n",
      "\n",
      "\n",
      "\n",
      "Curriculum Connections\n",
      "\n",
      "\n",
      "\n",
      "Social Studies\n",
      "\n",
      "\n",
      "\n",
      "Standard VI. Power, Authority, and Governance: Social studies programs should include experiences that provide for the study of how people create and change structures of power, authority, and governance.\n",
      "\n",
      "\n",
      "\n",
      "The Curriculum Standards for Social Studies (http://www.socialstudies.org/standards/strands/) are published by the National Council for Social Studies (http://ncss.org/).\n",
      "\n",
      "\n",
      "\n",
      "United States History\n",
      "\n",
      "\n",
      "\n",
      "Standard 27. Understands how the Cold War and conflicts in Korea and Vietnam influenced domestic and international politics\n",
      "\n",
      "\n",
      "\n",
      "Level IV [Grade 9-12]\n",
      "\n",
      "\n",
      "\n",
      "Benchmark 1. Understands U.S. foreign policy from the Truman administration to the Johnson administration\n",
      "\n",
      "\n",
      "\n",
      "Standard 30. Understands developments in foreign policy and domestic politics between the Nixon and Clinton presidencies\n",
      "\n",
      "\n",
      "\n",
      "Level IV [Grade 9-12]\n",
      "\n",
      "\n",
      "\n",
      "Benchmark 5. Understands the influence of U.S. foreign policy on international events from Nixon to Clinton\n",
      "\n",
      "\n",
      "\n",
      "Content Knowledge: A Compendium of Standards and Benchmarks for K-12 Education (Copyright 2000 McREL) is published online by Mid-continent Research for Education and Learning (McREL) (http://www.mcrel.org/standards-benchmarks ), 2550 S. Parker Road, Suite 500, Aurora, CO 80014; Telephone: 303/337-0990.\n",
      "\n",
      "\n",
      "\n",
      "World History\n",
      "\n",
      "\n",
      "\n",
      "Standard 44. Understands the search for community, stability, and peace in an interdependent world\n",
      "\n",
      "\n",
      "\n",
      "Level IV [Grade 9-12]\n",
      "\n",
      "\n",
      "\n",
      "Benchmark 11. Understands common arguments of opposition groups in various countries around the world, common solutions they offer, and the position of these ideas with regard to Western economic and strategic interests\n",
      "\n",
      "\n",
      "\n",
      "Content Knowledge: A Compendium of Standards and Benchmarks for K-12 Education (Copyright 2000 McREL) is published online by Mid-continent Research for Education and Learning (McREL) (http://www.mcrel.org/standards-benchmarks ), 2550 S. Parker Road, Suite 500, Aurora, CO 80014; Telephone: 303/337-0990.\n",
      "\n",
      "\n",
      "\n",
      "Civics\n",
      "\n",
      "\n",
      "\n",
      "III. How Does The Government Established By The Constitution Embody The Purposes, Values, And Principles Of American Democracy?\n",
      "\n",
      "\n",
      "\n",
      "4. Major responsibilities of the national government in domestic and foreign policy\n",
      "\n",
      "\n",
      "\n",
      "IV. What Is The Relationship Of The United States To Other Nations And To World Affairs?\n",
      "\n",
      "\n",
      "\n",
      "1. Nation-states\n",
      "\n",
      "\n",
      "\n",
      "2. Interactions among nation-states\n",
      "\n",
      "\n",
      "\n",
      "4. The historical context of United States foreign policy\n",
      "\n",
      "\n",
      "\n",
      "5. Making and implementing United States foreign policy\n",
      "\n",
      "\n",
      "\n",
      "6. The ends and means of United States foreign policy\n",
      "\n",
      "\n",
      "\n",
      "7. Impact of the American concept of democracy and individual rights on the world\n",
      "\n",
      "\n",
      "\n",
      "The National Standards for Civics and Government (http://www.civiced.org/index.php?page=stds) are published by the Center for Civic Education (http://www.civiced.org/).\n",
      "\n",
      "\n",
      "\n",
      "Discussion Questions\n",
      "\n",
      "\n",
      "\n",
      "1. Who is the leader of North Korea? According to the report, how do North Koreans regard this leader? What aspects of his personality are revealed in the program?\n",
      "\n",
      "\n",
      "\n",
      "2. According to the program, North Korea is a \"closed society.\" What does this mean?\n",
      "\n",
      "\n",
      "\n",
      "3. How does the report describe the history of U.S.-North Korea relations? According to the report: What tensions currently exist between these two nations? What humanitarian and political concerns exist in North Korea?\n",
      "\n",
      "\n",
      "\n",
      "4. Why do you think that North Korea invited the New York Philharmonic to play, and decided to open the Yongbyon nuclear facility to the media at this point in time? Why are these events historically and politically significant?\n",
      "\n",
      "\n",
      "\n",
      "5. Who is Madeline Albright? When and where did she meet with Kim Jong-Il?\n"
     ]
    }
   ],
   "source": [
    "print(tokenized_dataset['test'][0]['context'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "59cc9660",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(CNN) -- Trains and text messages made a deadly combination when two locomotives collided head-on last year near Los Angeles, California, witnesses told an investigative panel this week.\n",
      "\n",
      "\n",
      "\n",
      "Firefighters and investigators inspect the wreckage a day after a train collision in California killed 25 people.\n",
      "\n",
      "\n",
      "\n",
      "Metrolink commuter train engineer Robert Sanchez missed a stop signal while trading text messages with a friend on September 12, leading to a collision with a Union Pacific freight train that killed Sanchez and 24 other people in Chatsworth, California.\n",
      "\n",
      "\n",
      "\n",
      "The accident injured 101 people and caused $10.6 million in damages, according to a report by federal investigators.\n",
      "\n",
      "\n",
      "\n",
      "One National Transportation Safety Board member worries other disasters loom on the nation's rail system.\n",
      "\n",
      "\n",
      "\n",
      "\"One train, one day, one crew. It raises questions for me as to what the heck else is going on out there,\" said Kitty Higgins, chairwoman of a two-day NTSB hearing in Washington on the accident.\n",
      "\n",
      "\n",
      "\n",
      "Sanchez violated his employer's safety rules by even having a cell phone in the cab of the locomotive, a supervisor testified.  Watch what investigators found »\n",
      "\n",
      "\n",
      "\n",
      "Phone records show Sanchez was not only texting a friend just 22 seconds before the collision, but he also had made plans to allow the same friend to actually operate the train.\n",
      "\n",
      "\n",
      "\n",
      "This was a text conversation four days before the crash:\n",
      "\n",
      "\n",
      "\n",
      "[Sanchez to friend]: \"I'm REALLY looking forward to getting you in the cab and showing you how to run a locomotive.\"\n",
      "\n",
      "\n",
      "\n",
      "[Friend to Sanchez]: \"OMG dude me too. Running a locomotive. Having all of that in the palms of my hands.\"\n",
      "\n",
      "\n",
      "\n",
      "[Sanchez to friend]: \"I'm gonna do all the radio talkin'...ur gonna run the locomotive & I'm gonna tell u how to do it. \"\n",
      "\n",
      "\n",
      "\n",
      "At the hearing, officials said Sanchez had been caught with a cell phone twice before. Once another employee turned him in, another time a manager called his phone to see if it was with him in the train cab.\n",
      "\n",
      "\n",
      "\n",
      "\"The engineer's cell phone rang. It was in his briefcase on the other side of the train. I told the engineer that he was in violation of our policy,\" Rick Dahl, who was a safety manager with Metrolink at the time of the accident, told the NTSB investigative panel.\n",
      "\n",
      "\n",
      "\n",
      "Federal regulations do not cover cell phone use by train crews.\n",
      "\n",
      "\n",
      "\n",
      "Records also indicate Sanchez previously had allowed unauthorized people to ride in the cab, and one person even sat at the controls while the train was operating, investigators said.\n",
      "\n",
      "\n",
      "\n",
      "Phone company records indicate the Union Pacific freight train conductor, who was not named and who survived, also sent a text message about two minutes before the collision, but no other crew member sent or received any messages while on duty, investigators said.\n",
      "\n",
      "\n",
      "\n",
      "That train crew followed all signals and other procedures properly, according to an NTSB timeline.\n",
      "\n",
      "\n",
      "\n",
      "The Metrolink train stopped at a station for 57 seconds to allow passengers to exit and board the train, according to an animation of the timeline presented at the hearing.\n",
      "\n",
      "\n",
      "\n",
      "\"The engineer is required to call all signals and indications via radio,\" Dahl testified. Sanchez did not call any of the last three signals before the crash, investigators determined.\n",
      "\n",
      "\n",
      "\n",
      "The freight train was supposed to move onto a siding to allow the Metrolink train to pass, but it never got there because the commuter train ignored a stop signal and intercepted it at a curve. The freight train was just emerging from a tunnel in the rugged Topanga Canyon, and the trains were visible to each other in the curve for only about five seconds, according to the report.\n",
      "\n",
      "\n",
      "\n",
      "At the time of impact, the Metrolink train was traveling about 42 mph and the Union Pacific train 41 mph. The freight train braked for two seconds before impact; the commuter train didn't brake at all, according to onboard data recorders.\n",
      "\n",
      "\n",
      "\n",
      "Investigators found no problems with the signals, the trains' brakes and radios or the tracks. The Union Pacific conductor's blood and urine tested positive for marijuana, but\n"
     ]
    }
   ],
   "source": [
    "print(tokenized_dataset['test'][3]['context'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7a6d1014",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive answer: [CLS]\n",
      "Negative answer: [CLS]\n"
     ]
    }
   ],
   "source": [
    "positive_question = 'What does Rihanna think about the heavy chain?'\n",
    "negative_question = 'What is the U.S. military doing?'\n",
    "positive_context = tokenized_dataset['test'][0]['context']\n",
    "negative_context = tokenized_dataset['test'][3]['context']\n",
    "\n",
    "positive_encoding = tokenizer.encode_plus(text=positive_question, text_pair=positive_context)\n",
    "negative_encoding = tokenizer.encode_plus(text=negative_question, text_pair=negative_context)\n",
    "positive_inputs = positive_encoding['input_ids']\n",
    "negative_inputs = negative_encoding['input_ids']\n",
    "\n",
    "positive_scores = model(input_ids=tf.convert_to_tensor(positive_inputs))\n",
    "negative_scores = model(input_ids=tf.convert_to_tensor(negative_inputs))\n",
    "start_index_p = tf.math.argmax(positive_scores['start_logits'], axis=1).numpy()[0]\n",
    "end_index_p = tf.math.argmax(positive_scores['end_logits'], axis=1).numpy()[0]\n",
    "start_index_n = tf.math.argmax(negative_scores['start_logits'], axis=1).numpy()[0]\n",
    "end_index_n = tf.math.argmax(negative_scores['end_logits'], axis=1).numpy()[0]\n",
    "positive_answer = tokenizer.decode(positive_inputs[start_index_p:end_index_p + 1])\n",
    "negative_answer = tokenizer.decode(negative_inputs[start_index_n:end_index_n + 1])\n",
    "\n",
    "print(f'Positive answer: {positive_answer}')\n",
    "print(f'Negative answer: {negative_answer}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "3a5708a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All PyTorch model weights were used when initializing TFAlbertForSequenceClassification.\n",
      "\n",
      "All the weights of TFAlbertForSequenceClassification were initialized from the PyTorch model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFAlbertForSequenceClassification for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "classifier_tok_checkpoint = 'albert/albert-base-v2'\n",
    "classifier_model_checkpoint = './albert/albert-base-v2_finetuned_sentiment/checkpoint-10000/'\n",
    "\n",
    "classifier_tokenizer = AutoTokenizer.from_pretrained(classifier_tok_checkpoint)\n",
    "classifier_model = TFAutoModelForSequenceClassification.from_pretrained(classifier_model_checkpoint, local_files_only=True, num_labels=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "763ef778",
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_encoded = tokenizer(positive_answer, truncation=True, padding='max_length', max_length=35, return_tensors='tf')['input_ids']\n",
    "negative_encoded = tokenizer(negative_answer, truncation=True, padding='max_length', max_length=35, return_tensors='tf')['input_ids']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "a9a5974b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive article predicted class: 0\n",
      "Positive article predicted logits: [0.7568402  0.04390718]\n",
      "Negative article predicted class: 0\n",
      "Negative article predicted logits: [0.60612404 0.01932076]\n"
     ]
    }
   ],
   "source": [
    "positive_pred = classifier_model(input_ids=positive_encoded).logits.numpy()\n",
    "negative_pred = classifier_model(input_ids=negative_encoded).logits.numpy()\n",
    "\n",
    "print(f'Positive article predicted class: {positive_pred.argmax()}')\n",
    "print(f'Positive article predicted logits: {positive_pred[0]}')\n",
    "print(f'Negative article predicted class: {negative_pred.argmax()}')\n",
    "print(f'Negative article predicted logits: {negative_pred[0]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "359d72a1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "501r",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
